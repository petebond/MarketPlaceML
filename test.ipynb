{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import pickle as pkl\n",
    "\n",
    "\n",
    "class ML():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the class.\n",
    "        \"\"\"\n",
    "        print(\"Initializing...\")\n",
    "\n",
    "    def get_data(self, table_name: str, the_columns: list):\n",
    "        \"\"\"When there's no csv, we go online to get the data.\n",
    "\n",
    "        Args:\n",
    "            - None\n",
    "\n",
    "        Returns:\n",
    "            - None\n",
    "        \"\"\"\n",
    "        load_dotenv()\n",
    "        DATABASE_TYPE = os.environ.get('DATABASE_TYPE')\n",
    "        DBAPI = os.environ.get('DBAPI')\n",
    "        ENDPOINT = os.environ.get('ENDPOINT')\n",
    "        DBUSER = os.environ.get('DBUSER')\n",
    "        DBPASSWORD = os.environ.get('DBPASSWORD')\n",
    "        PORT = 5432\n",
    "        DATABASE = os.environ.get('DATABASE')\n",
    "        engine = create_engine(f\"{DATABASE_TYPE}+{DBAPI}://{DBUSER}:\"\n",
    "                                    f\"{DBPASSWORD}@{ENDPOINT}:\"\n",
    "                                    f\"{PORT}/{DATABASE}\")\n",
    "        engine.connect()\n",
    "        df = pd.read_sql_table(table_name,\n",
    "                               engine,\n",
    "                               columns=the_columns)\n",
    "        return df\n",
    "\n",
    "    def remove_n_a_rows(self, df: pd.DataFrame, column: str):\n",
    "        \"\"\"\n",
    "        Scan the column for records with all N/As. Delete.\n",
    "\n",
    "        Args:\n",
    "            - column (str): The column being scanned.\n",
    "        \"\"\"\n",
    "        # Swap N/A for the pandas nan, so we can drop them\n",
    "        temp_df = df[column].replace('N/A', np.nan)\n",
    "        temp_df = temp_df.dropna()\n",
    "        # Create a new df with only the records without the nans\n",
    "        clean_df = pd.merge(temp_df, df,\n",
    "                            left_index=True, right_index=True)\n",
    "        # The merge creates a duplicate column. Remove it.\n",
    "        clean_df.drop(column + '_x', inplace=True, axis=1)\n",
    "        # Rename the remaining category column\n",
    "        clean_df.rename(columns={column + '_y': column}, inplace=True)\n",
    "        # Commit the cleansed data to the dataframe\n",
    "        df = clean_df\n",
    "        return df\n",
    "\n",
    "    def split_heirarchies(self, df, col: str, character: str, no_cols: int):\n",
    "        \"\"\"\n",
    "        Takes in a column name and splits data to columns based on sep. char.\n",
    "\n",
    "        Args:\n",
    "            col (str): _description_\n",
    "            character (str): _description_\n",
    "            no_cols (int): _description_\n",
    "        \"\"\"\n",
    "        df[[col+str(i) for i in range(no_cols)]] = (\n",
    "            df[col].str.split(character, expand=True))\n",
    "        df = df.drop(col, axis=1)\n",
    "        if col == 'category':\n",
    "            for i in range(no_cols):\n",
    "                if i > 0:\n",
    "                    df = df.drop(col+str(i), axis=1)\n",
    "        return df\n",
    "    \n",
    "    def remove_currency_characters_from_price(self, df):\n",
    "        \"\"\"\n",
    "        Remove the currency characters from the price column.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): The dataframe to clean.\n",
    "        \"\"\"\n",
    "        df['price'] = df['price'].str.replace('Â£', '')\n",
    "        df['price'] = df['price'].str.replace(',', '')\n",
    "        df = df.astype({\"price\": float}, errors='raise')\n",
    "        df.reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def remove_price_outliers(self, df):\n",
    "        \"\"\"\n",
    "        Remove the outliers from the price column.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): The dataframe to clean.\n",
    "        \"\"\"\n",
    "        df = df[df['price'] < 1000]\n",
    "        df = df[df['price'] > 1]\n",
    "        return df\n",
    "\n",
    "    def separate_X_y_data(self, df, x_col: str, y_col: str):\n",
    "        \"\"\"\n",
    "        Create a linear regression model.\n",
    "        \"\"\"\n",
    "        X = df[[x_col]]\n",
    "        y = df[y_col]\n",
    "        X = pd.get_dummies(X, drop_first=True)\n",
    "        return X, y\n",
    "\n",
    "    def create_linear_regression_model(self, X, y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        regr = LinearRegression()\n",
    "        regr.fit(X_train, y_train)\n",
    "        y_pred = regr.predict(X_test)\n",
    "        # The coefficients\n",
    "        print(\"Coefficients: \\n\", regr.coef_)\n",
    "        # The mean squared error\n",
    "        print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "        # The coefficient of determination: 1 is perfect prediction\n",
    "        print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))\n",
    "        return regr, y_pred, y_test\n",
    "\n",
    "    def merge_dfs(self, df1, df2, left_on: str, right_on: str):\n",
    "        return df1.merge(df2,\n",
    "                         how='inner',\n",
    "                         left_on=left_on,\n",
    "                         right_on=right_on)\n",
    "\n",
    "\n",
    "\n",
    "    def create_dict_of_categories(self, df: pd, column_to_index: str) -> None:\n",
    "        categories_dict = set(df[column_to_index])\n",
    "        categories_dict = {k: v for v, k in enumerate(categories_dict)}\n",
    "        return categories_dict\n",
    "\n",
    "    def create_df_of_image_paths(self) -> None:\n",
    "        image_paths = glob.glob('resized/*.jpg')\n",
    "        image_paths = [x.split('/')[-1] for x in image_paths]\n",
    "        image_paths = [x.split('.')[0] for x in image_paths]\n",
    "        return image_paths\n",
    "\n",
    "    def numberise_categories(self, df, column_to_index, categories_dict, image_paths) -> None:\n",
    "        # replace the category column with the index of the category\n",
    "        df[column_to_index] = df[column_to_index].map(categories_dict)\n",
    "        image_df = pd.DataFrame({'image_path': image_paths})\n",
    "        # merge the image_df with the df\n",
    "        images_category_df = image_df.merge(df, how='inner', left_on='image_path', right_on='id_x')\n",
    "        # drop all columns except the image_path and the category\n",
    "        images_category_df = images_category_df[['image_path', column_to_index]]\n",
    "        return images_category_df\n",
    "        \n",
    "    def prepare_image_category_datapoint(self, index: int, images_category_df) -> None:\n",
    "        image = images_category_df['image_path'][index]\n",
    "        image = Image.open('resized/' + image + '.jpg')\n",
    "        image = np.array(image)\n",
    "        image = torch.from_numpy(image)\n",
    "        image = torch.flatten(image)\n",
    "        category = images_category_df['category'][index]\n",
    "        return (image, category)\n",
    "\n",
    "    def test_split(self, matrix, target, test_proportion):\n",
    "        ratio = int(matrix.shape[0]/test_proportion) #should be int\n",
    "        X_train = matrix[ratio:]\n",
    "        X_test =  matrix[:ratio]\n",
    "        y_train = target[ratio:]\n",
    "        y_test =  target[:ratio]\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def save_model(self, model, path):\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create instance of ML class\n",
    "    fb = ML()\n",
    "    # Get product data from database\n",
    "    # test if local csv is present\n",
    "    if os.path.isfile('data/Products.csv'):\n",
    "        products_df = pd.read_csv('data/Products.csv')\n",
    "    else:\n",
    "        print(\"Downloading Product Data...\")\n",
    "        products_df = fb.get_data('products', [\"id\",\n",
    "                                               \"product_name\",\n",
    "                                               \"category\",\n",
    "                                               \"product_description\",\n",
    "                                               \"price\",\n",
    "                                               \"location\",\n",
    "                                               \"page_id\",\n",
    "                                               \"create_time\"])\n",
    "    # Clean the product data\n",
    "    print(\"Cleaning Product Data...\")\n",
    "    print(\"Remove N/A rows...\")\n",
    "    products_df = fb.remove_n_a_rows(products_df, 'category')\n",
    "    print(\"Split category into heirarchies...\")\n",
    "    num_cols = products_df['category'].str.count('/').max()+1\n",
    "    products_df = fb.split_heirarchies(products_df, 'category', '/', num_cols)\n",
    "    products_df.rename(columns={\"category0\": \"category\"}, inplace=True)\n",
    "    print(\"Remove currency characters from price...\")\n",
    "    products_df = fb.remove_currency_characters_from_price(products_df)\n",
    "    print(\"Remove price outliers...\")\n",
    "    products_df = fb.remove_price_outliers(products_df)\n",
    "    \n",
    "    # Give the option to display the category data distribution\n",
    "    print(\"Would you like to view the category price distribution?\")\n",
    "    answer = input(\"(y/n): \")\n",
    "    if answer[0].lower() == 'y':\n",
    "        sns.boxplot(x='category', y='price', data=products_df)\n",
    "        plt.show()\n",
    "    \n",
    "    # Create a linear regression model\n",
    "    print(\"Creating Linear Regression Model...\")\n",
    "    X, y = fb.separate_X_y_data(products_df, 'category', 'price')\n",
    "    # Test train split\n",
    "    print(\"Split test and train, and then train the model...\")\n",
    "    fb.create_linear_regression_model(X, y)\n",
    "\n",
    "    # Create a logistic regression model\n",
    "    print(\"Creating Logistic Regression Model...\")\n",
    "    # Test if local csv is present\n",
    "    if os.path.isfile('data/Images.csv'):\n",
    "        image_df = pd.read_csv('data/Images.csv')\n",
    "    else:\n",
    "        # Get image data from database\n",
    "        print(\"Downloading Image Data...\")\n",
    "        image_df = fb.get_data('images', [\"id\", \n",
    "                                          \"product_id\",\n",
    "                                          \"bucket_link\",\n",
    "                                          \"image_ref\",\n",
    "                                          \"create_time\"])\n",
    "    # Merge image data with product categories\n",
    "    print(\"Merging Image Data with Product Categories...\")\n",
    "    df = fb.merge_dfs(image_df, products_df, 'product_id', 'id')\n",
    "\n",
    "    cat_dict = fb.create_dict_of_categories(df, 'category')\n",
    "    img_paths = fb.create_df_of_image_paths()\n",
    "    img_cats_df = fb.numberise_categories(df, 'category', cat_dict, img_paths)\n",
    "\n",
    "    # Shuffle the data\n",
    "    print(\"Shuffling the data...\")\n",
    "    complete_dataset = []\n",
    "    array_size = 49152\n",
    "    n = len(img_cats_df)\n",
    "    X = np.zeros((n, array_size))\n",
    "    y = np.zeros(n)\n",
    "\n",
    "    # create list of indexes to randomise\n",
    "    indexes = list(range(n))\n",
    "    random.shuffle(indexes)\n",
    "\n",
    "    for idx in indexes:\n",
    "        complete_dataset.append(fb.prepare_image_category_datapoint(idx, img_cats_df))\n",
    "        \n",
    "    for idx in range(n):    \n",
    "        features, label = complete_dataset[idx]  \n",
    "        X[idx, :] = features\n",
    "        y[idx] = label\n",
    "    \n",
    "    # test train split\n",
    "    print(\"Splitting test and train...\")\n",
    "    X_train, X_test, y_train, y_test = fb.test_split(X, y, 5)\n",
    "\n",
    "    choice = input(\"Would you like to train the model? (y/n): \")\n",
    "    if choice[0].lower() == 'y':\n",
    "        print(\"Training the model...\")\n",
    "        print(\"start the timer...\")\n",
    "        start = time.time()\n",
    "        model = LogisticRegression(max_iter=100)\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\"stop the timer...\")\n",
    "        end = time.time()\n",
    "        print(\"time taken: \", end - start)\n",
    "\n",
    "        # make predictions\n",
    "        print(\"Making predictions...\")\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        # evaluate the model\n",
    "        print(\"Evaluating the model...\")\n",
    "        score = model.score(X_test, y_test)\n",
    "        print(score)\n",
    "\n",
    "        # Show the confusion matrix\n",
    "        print(\"Showing the confusion matrix...\")\n",
    "        cm = metrics.confusion_matrix(y_test, predictions)\n",
    "        plt.figure(figsize=(13,13))\n",
    "        sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "        plt.ylabel('Actual label');\n",
    "        plt.xlabel('Predicted label');\n",
    "        all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "        plt.title(all_sample_title, size = 15);\n",
    "        plt.show()\n",
    "\n",
    "        # Show the categories, for comparison   \n",
    "        print(\"Showing the categories...\")\n",
    "        print(cat_dict.keys())\n",
    "\n",
    "    choice = input(\"Would you like to save the image models? (y/n): \")\n",
    "    if choice[0].lower() == 'y':\n",
    "        print(\"Saving the model...\")\n",
    "        file_object = open(\"models/image_model_X.pkl\", \"wb\")\n",
    "        pkl.dump(X, file_object)\n",
    "        file_object.close()\n",
    "\n",
    "        file_object = open(\"models/image_model_y.pkl\", \"wb\")\n",
    "        pkl.dump(y, file_object)\n",
    "        file_object.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "567be9f4e52cd72172dc0da57d5c2685b0d4d75f3caa699fd3f323a24444e908"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
