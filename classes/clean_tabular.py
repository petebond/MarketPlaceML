from sqlalchemy import create_engine
import pandas as pd
import os
from dotenv import load_dotenv
import numpy as np
import re
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
import json
import missingno as msno

class Marketplace():
    """
    Clean provided dataset and prepare for ML

    Process:
        - Check for existing downloaded data
            - download if not present
            - import from csv if present
        - Remove N/A records
        - Split Category and Product_name data
            - store each subsection in its own column
        - Remove currency symbols
        - Replace categories with numbers
        - Get longitude and latitude from location text
        - Export new data to csv and categories to json

    Args:
        - None

    Returns:
        - None
    """

    def __init__(self):
        """
        Initialise new Marketplace object
        """
        pass

    def not_already_downloaded(self) -> bool:
        """
        Checks for presence of csv file of already processed data

        Args:
            - None

        Returns:
            - Bool: True if no csv is present
        """
        if os.path.exists('data/cleaned.csv'):
            print("Existing data found")
            return False
        else:
            print("No csv present")
            return True

    def load_all_existing_data_to_dfs(self):
        """
        If csv information available, loads it to num_df

        Args:
            - None

        Returns:
            - None
        """
        self.num_df = pd.read_csv(
                        'data/cleaned.csv',
                        header=0,
                        delimiter=",",
                        engine='python')
        with open('data/category.json', 'r') as jf:
            self.cat_headings = dict(json.load(jf))
        with open('data/minor_category.json', 'r') as jf:
            self.minor_cat_headings = dict(json.load(jf))
        with open('data/sub_category.json', 'r') as jf:
            self.sub_cat_headings = dict(json.load(jf))

    def connect_to_RDS_engine(self):
        """
        When there's no csv, we go online to get the data.

        Args:
            - None

        Returns:
            - None
        """
        load_dotenv()
        DATABASE_TYPE = os.environ.get('DATABASE_TYPE')
        DBAPI = os.environ.get('DBAPI')
        ENDPOINT = os.environ.get('ENDPOINT')
        DBUSER = os.environ.get('DBUSER')
        DBPASSWORD = os.environ.get('DBPASSWORD')
        PORT = 5432
        DATABASE = os.environ.get('DATABASE')
        engine = create_engine(f"{DATABASE_TYPE}+{DBAPI}://{DBUSER}:"
                                    f"{DBPASSWORD}@{ENDPOINT}:"
                                    f"{PORT}/{DATABASE}")
        engine.connect()
        main_df = pd.read_sql_table(
            'products', self.engine,
            columns=["id", "product_name", "category", "product_description",
                     "price", "location",
                     "page_id", "create_time"])
        return main_df

    def remove_n_a_records(self, column: str):
        """
        Scan the column for records with all N/As. Get rid of them

        Args:
            column (str): The column currently being scanned.
        """
        # Swap N/A for the pandas nan, so we can drop them
        temp_df = self.main_df[column].replace('N/A', np.nan)
        temp_df = temp_df.dropna()
        # Create a new df with only the records without the nans
        clean_df = pd.merge(temp_df, self.main_df,
                            left_index=True, right_index=True)
        # The merge creates a duplicate column. Remove it.
        clean_df.drop(column + '_x', inplace=True, axis=1)
        # Rename the remaining category column
        clean_df.rename(columns={column + '_y': column}, inplace=True)
        # Commit the cleansed data to the dataframe
        self.main_df = clean_df

    def split_heirarchies(self, col: str, character: str, no_cols: int):
        """
        Takes in a column name and splits data to columns based on sep. char.

        Args:
            col (str): _description_
            character (str): _description_
            no_cols (int): _description_
        """
        self.main_df[[col+str(i) for i in range(no_cols)]] = (
            self.main_df[col].str.split(character, expand=True))
        self.main_df = self.main_df.drop(col, axis=1)
        if col == 'category':
            for i in range(no_cols):
                if i > 2:
                    self.main_df = self.main_df.drop(col+str(i), axis=1)

    def clean_columns(self, num: int):
        """
        Removes unnecessary columns generated by split_heirarchies func.
        Renames product_name and category columns accordingly

        Args:
            num (int): The number of columns to keep
        """
        # categories - remove anything after category_2
        cols = [('product_name' + str(i)) for i in range(1, (num))]
        for column in cols:
            self.main_df = self.main_df.drop(column, axis=1)
        self.main_df = self.main_df.rename(
            columns={'product_name0': 'product_name',
                     'category0': 'category',
                     'category1': 'sub_category',
                     'category2': 'minor_category'})
        self.main_df['category'] = self.main_df['category'].apply(
            lambda x: x.strip(' |') if not(pd.isnull(x)) else x)
        self.main_df['sub_category'] = self.main_df['sub_category'].apply(
            lambda x: x.strip(' |') if not(pd.isnull(x)) else x)
        self.main_df['minor_category'] = self.main_df['minor_category'].apply(
            lambda x: x.strip(' |') if not(pd.isnull(x)) else x)
        self.main_df['product_name'] = self.main_df['product_name'].apply(
            lambda x: x.strip(' |') if not(pd.isnull(x)) else x)
        # Remove currency characters and leave only digits (and dec point)
        trim = re.compile(r'[^\d.]+')
        self.main_df['price'] = self.main_df['price'].apply(
            lambda x: trim.sub('', x) if not(pd.isnull(x)) else x)

    def create_num_df(self):
        """
        Calls the replace_words_with_numbers function as needed
        """
        self.num_df = self.main_df.copy()
        self.num_df = self.replace_words_with_numbers(
            self.num_df, 'category')
        self.num_df = self.replace_words_with_numbers(
            self.num_df, 'sub_category')
        self.num_df = self.replace_words_with_numbers(
            self.num_df, 'minor_category')

    def replace_words_with_numbers(self, df: pd, column: str) -> pd:
        """
        Iterates through the column and replaces category information
        with numbers in readiness for ML analysis

        Args:
            df (pd): the dataframe, passed in to the function
            column (str): the name of the column to be processed

        Returns:
            df (pd): The same dataframe, but with numbers
        """
        categories = set(df[column])
        categories = {k: v for v, k in enumerate(categories)}
        df = df.replace(categories)
        self.store_category_as_json(categories, column)
        return df
    
    def create_cat_df(self):
        """
        Leaves us with just the price and category columns
        """
        print(self.num_df.columns)
        self.num_df = self.num_df.dropna()
        self.num_df = self.num_df.drop(
            ['product_description',
            'location',
            'page_id',
            'create_time',
            'product_name',
            'sub_category',
            'minor_category'],
            axis=1)
        print(msno.matrix(self.num_df))

    def store_category_as_json(self, category: dict, name: str):
        """
        There's no point having all these numbers in the dataframe, if
        we don't know what those numbers mean. This procedure stores the
        dictionary of categories as a json file in the data directory.

        Args:
            category (dict): Dictionary of the set of values in the column
            name (str): Name of the file to be created
        """
        with open(f'data/{name}.json', 'w') as jf:
            json.dump(category, jf)

    def geocode_locations(self):
        """
        Uses the geocode library to get the long and lat information from
        the location field of the df

        Args:
            None

        Returns:
            None
        """
        self.locator = Nominatim(user_agent='aicore_cleaner')
        self.geocode = RateLimiter(self.locator.geocode,
                                   min_delay_seconds=0.2,
                                   return_value_on_exception=None)
        self.num_df['geocode'] = self.num_df['location'].apply(self.geocode)
        self.num_df['long_lat'] = self.num_df['geocode'].apply(
            lambda loc: tuple(loc.point) if loc else None)



